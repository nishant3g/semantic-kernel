{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using service type: Service.AzureOpenAI\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.utils.logging import setup_logging\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import (\n",
    "    AzureChatPromptExecutionSettings,\n",
    ")\n",
    "\n",
    "# Make sure paths are correct for the imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "\n",
    "sys.path.append(grandparent_dir)\n",
    "\n",
    "from services import Service\n",
    "\n",
    "from samples.service_settings import ServiceSettings\n",
    "\n",
    "service_settings = ServiceSettings()\n",
    "\n",
    "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "selectedService = (\n",
    "    Service.AzureOpenAI\n",
    "    if service_settings.global_llm_service is None\n",
    "    else Service(service_settings.global_llm_service.lower())\n",
    ")\n",
    "print(f\"Using service type: {selectedService}\")\n",
    "\n",
    "# Initialize the kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Remove all services so that this cell can be re-run without restarting the kernel\n",
    "kernel.remove_all_services()\n",
    "\n",
    "service_id = None\n",
    "if selectedService == Service.OpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        OpenAIChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )\n",
    "elif selectedService == Service.AzureOpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant > Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "\n",
    "# Set the logging level for  semantic_kernel.kernel to DEBUG.\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s - %(name)s:%(lineno)d - %(levelname)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logging.getLogger(\"kernel\").setLevel(logging.DEBUG)\n",
    "chat_completion : AzureChatCompletion = kernel.get_service(type=ChatCompletionClientBase)\n",
    "from typing import Annotated\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "class LightsPlugin:\n",
    "    lights = [\n",
    "        {\"id\": 1, \"name\": \"Table Lamp\", \"is_on\": False},\n",
    "        {\"id\": 2, \"name\": \"Porch light\", \"is_on\": False},\n",
    "        {\"id\": 3, \"name\": \"Chandelier\", \"is_on\": True},\n",
    "    ]\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"get_lights\",\n",
    "        description=\"Gets a list of lights and their current state\",\n",
    "    )\n",
    "    def get_state(\n",
    "        self,\n",
    "    ) -> str:\n",
    "        \"\"\"Gets a list of lights and their current state.\"\"\"\n",
    "        return self.lights\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"change_state\",\n",
    "        description=\"Changes the state of the light\",\n",
    "    )\n",
    "    def change_state(\n",
    "        self,\n",
    "        id: int,\n",
    "        is_on: bool,\n",
    "    ) -> str:\n",
    "        \"\"\"Changes the state of the light.\"\"\"\n",
    "        for light in self.lights:\n",
    "            if light[\"id\"] == id:\n",
    "                light[\"is_on\"] = is_on\n",
    "                return light\n",
    "        return None\n",
    "# Add the plugin to the kernel\n",
    "kernel.add_plugin(\n",
    "    LightsPlugin(),\n",
    "    plugin_name=\"Lights\",\n",
    ")\n",
    "execution_settings = AzureChatPromptExecutionSettings()\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "\n",
    "## Initiate a back-and-forth chat\n",
    "userInput = None\n",
    "while True:\n",
    "    # Collect user input\n",
    "    userInput = input(\"User > \")\n",
    "\n",
    "    # Terminate the loop if the user says \"exit\"\n",
    "    if userInput == \"exit\":\n",
    "        break\n",
    "\n",
    "    # Add user input to the history\n",
    "    history.add_user_message(userInput)\n",
    "\n",
    "    # Get the response from the AI\n",
    "    result = await chat_completion.get_chat_message_content(\n",
    "        chat_history=history,\n",
    "        settings=execution_settings,\n",
    "        kernel=kernel,\n",
    "    )\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Assistant > \" + str(result))\n",
    "\n",
    "    # Add the message from the agent to the chat history\n",
    "    history.add_message(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatMessageContent(inner_content=None, ai_model_id=None, metadata={}, content_type='message', role=<AuthorRole.USER: 'user'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Hi', encoding=None)], encoding=None, finish_reason=None, status=None), ChatMessageContent(inner_content=ChatCompletion(id='chatcmpl-BO4w8qok7QWAA8UszTTKUkZkmiNg0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1745078548, model='gpt-4o-2024-11-20', object='chat.completion', service_tier=None, system_fingerprint='fp_ee1d74bde0', usage=CompletionUsage(completion_tokens=11, prompt_tokens=71, total_tokens=82, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]), ai_model_id='gpt-4o', metadata={'logprobs': None, 'id': 'chatcmpl-BO4w8qok7QWAA8UszTTKUkZkmiNg0', 'created': 1745078548, 'system_fingerprint': 'fp_ee1d74bde0', 'usage': CompletionUsage(prompt_tokens=71, completion_tokens=11)}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Hello! How can I assist you today?', encoding=None)], encoding=None, finish_reason=<FinishReason.STOP: 'stop'>, status=None)]\n"
     ]
    }
   ],
   "source": [
    "print(history.messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
